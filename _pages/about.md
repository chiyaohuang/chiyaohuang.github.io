---
permalink: /
title: "Chi-Yao Huang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi there, I am currently an RA working with [Yezhou Yang](https://yezhouyang.engineering.asu.edu/) at Arizona State University. My research focuses on semantic SLAM, learning-based 3D reconstruction, and spatial AI. Before coming to ASU, I was a foundational VR/AR engineer in [HTC VIVE](https://www.vive.com/us/) for three years. I developed a VR/AR tracking technique, which is used in almost all VR/AR products in HTC VIVE. Previously, I received my MS at National Taiwan University with my advisor [Han-Pang Huang](http://ai.robo.ntu.edu.tw/en/personal.php?id=33).



Research
------
In 2015, giving a TED talk "How we teach computer to see," Lee Fei Fei founded ImageNet to facilitate human life by teaching robots to understand images. After seven years, however, "Do robots really understand what they see?" In my opinion, the answer is no. So far, robots still show limited understanding of what they see. They can tell the types of objects in the image, but they have difficulty understanding their shape in space. In short, robots don't realize the concept of space so that they can't really help humans. Therefore, my research career aims to teach robots to understand space. In this way, robots can understand the concept of space and truly help human life.

